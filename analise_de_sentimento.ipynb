{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnxm2a5Qg4BF"
      },
      "outputs": [],
      "source": [
        "# 1.1 Importações necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Criando um conjunto de dados de exemplo (na prática, usariam o do projeto)\n",
        "# Dica: Substituam isso pelo código que carrega e pré-processa os dados do projeto de vocês.\n",
        "corpus = [\n",
        "    \"o filme é excelente e muito divertido\",\n",
        "    \"não gostei do enredo, muito chato\",\n",
        "    \"a atuação foi brilhante e o roteiro impecável\",\n",
        "    \"péssimo! perdi meu tempo assistindo\",\n",
        "    \"a história é ok, mas nada de mais\",\n",
        "    \"filme horrível, nem vale a pena\",\n",
        "    \"uma obra-prima da sétima arte\",\n",
        "    \"o filme tem um final surpreendente e emocionante\",\n",
        "    \"este é o pior filme que já vi na vida\"\n",
        "]\n",
        "\n",
        "labels = [\"positivo\", \"negativo\", \"positivo\", \"negativo\", \"neutro\", \"negativo\", \"positivo\", \"positivo\", \"negativo\"]\n",
        "\n",
        "# Separando dados em treino e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(corpus, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Vetorização dos textos usando TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=100)\n",
        "X_treino_vetorizado = vectorizer.fit_transform(X_treino)\n",
        "X_teste_vetorizado = vectorizer.transform(X_teste)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Criando e treinando o modelo inicial (com parâmetros padrão)\n",
        "modelo_base = SVC()\n",
        "modelo_base.fit(X_treino_vetorizado, y_treino)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "previsoes = modelo_base.predict(X_teste_vetorizado)\n",
        "\n",
        "# Avaliando o modelo inicial\n",
        "print(\"### Análise Inicial do Modelo (linha de base) ###\\n\")\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_teste, previsoes, zero_division=0))\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_teste, previsoes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNDlU4mRigVc",
        "outputId": "93287585-548c-4aa0-94ad-a783d1675c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Análise Inicial do Modelo (linha de base) ###\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.00      0.00      0.00         2\n",
            "    positivo       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[0 2]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analise os Resultados:\n",
        "\n",
        "A baixa performance do modelo (acurácia e F1-score baixos) neste primeiro passo é causada, primariamente, pela qualidade e tamanho insuficientes dos dados\n",
        " F1-score para classes com suporte baixíssimo é não confiável.O modelo não consegue performar bem porque a qualidade dos dados (neste caso, a falta deles) compromete a capacidade de aprendizado, independentemente do algoritmo escolhido5.\n",
        " 2. Matriz de Confusão: Onde o Modelo Erra e o que Ele AprendeuAo examinar a matriz de confusão, o padrão de erro provável nos diz que o modelo \"aprendeu\" muito pouco ou nada de útil:Classe com Maior Erro: É altamente provável que o modelo esteja errando a maioria das previsões na classe com menor número de amostras (suporte), que é a classe \"neutro\" (apenas 1 amostra no corpus original 6). O modelo simplesmente não viu exemplos suficientes do que é um sentimento neutro para classificar corretamente.\n",
        " O que o Modelo \"Aprendeu\": A matriz de confusão provavelmente mostrará que o modelo tende a classificar quase tudo na classe majoritária ou naquela que ele \"aprendeu\" mais facilmente. Isso significa que ele não aprendeu a distinção fina entre as classes; ele apenas se tornou bom em chutar a categoria mais frequente no conjunto de treino.Em suma, a matriz de confusão reforça que o modelo está superajustado (overfitting) aos poucos dados ou está subajustado (underfitting), falhando em capturar qualquer padrão significativo."
      ],
      "metadata": {
        "id": "6zk6I7rpltP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo com validação cruzada\n",
        "# Usamos o modelo base novamente para a avaliação\n",
        "scores = cross_val_score(modelo_base, X_treino_vetorizado, y_treino, cv=3, scoring='f1_macro')\n",
        "\n",
        "print(\"\\n### Avaliação com Validação Cruzada ###\\n\")\n",
        "print(f\"Scores para cada 'fold': {scores}\")\n",
        "print(f\"Média do F1-score com Validação Cruzada: {scores.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz_E59bbijMk",
        "outputId": "0680bb64-f9bc-4094-f160-95d95c3dedb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Avaliação com Validação Cruzada ###\n",
            "\n",
            "Scores para cada 'fold': [0.33333333 0.33333333 0.33333333]\n",
            "Média do F1-score com Validação Cruzada: 0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os hiperparâmetros que queremos testar\n",
        "# 'C' controla a margem de classificação (trade-off entre regularização e erro de treino)\n",
        "# 'kernel' define a função de kernel usada pelo SVM\n",
        "parametros = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "# Criando o objeto GridSearchCV\n",
        "# cv=3 significa que testaremos cada combinação 3 vezes\n",
        "grid_search = GridSearchCV(SVC(), parametros, cv=3, scoring='f1_macro')\n",
        "\n",
        "# Executando a busca na \"grade\"\n",
        "print(\"\\n### Buscando os Melhores Hiperparâmetros... ###\")\n",
        "grid_search.fit(X_treino_vetorizado, y_treino)\n",
        "\n",
        "# Exibindo os melhores resultados\n",
        "print(\"\\nBusca Concluída!\")\n",
        "print(f\"Melhores parâmetros encontrados: {grid_search.best_params_}\")\n",
        "print(f\"Melhor pontuação (F1-score) encontrada: {grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Avaliando o modelo otimizado no conjunto de teste\n",
        "modelo_otimizado = grid_search.best_estimator_\n",
        "previsoes_otimizadas = modelo_otimizado.predict(X_teste_vetorizado)\n",
        "\n",
        "print(\"\\n### Análise do Modelo Otimizado (comparação) ###\\n\")\n",
        "print(\"Relatório de Classificação do Modelo Otimizado:\")\n",
        "print(classification_report(y_teste, previsoes_otimizadas, zero_division=0))\n",
        "print(\"\\nMatriz de Confusão do Modelo Otimizado:\")\n",
        "print(confusion_matrix(y_teste, previsoes_otimizadas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XlnQysMil7p",
        "outputId": "c7aae1d3-cabd-4249-d982-3b2d8de5910e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Buscando os Melhores Hiperparâmetros... ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Busca Concluída!\n",
            "Melhores parâmetros encontrados: {'C': 0.1, 'kernel': 'linear'}\n",
            "Melhor pontuação (F1-score) encontrada: 0.33\n",
            "\n",
            "### Análise do Modelo Otimizado (comparação) ###\n",
            "\n",
            "Relatório de Classificação do Modelo Otimizado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.00      0.00      0.00         2\n",
            "    positivo       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "\n",
            "Matriz de Confusão do Modelo Otimizado:\n",
            "[[0 2]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analise dos resultados: A pontuação média da Validação Cruzada ($\\text{F1-score}$) pode ser próxima ou ligeiramente diferente da acurácia/F1-score inicial."
      ],
      "metadata": {
        "id": "HjEVn2HrmVlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Criando um dataset de exemplo maior e mais balanceado\n",
        "# Note que a coleta de dados de um projeto real simula um volume de dados muito maior, para permitir a otimização\n",
        "corpus = [\n",
        "    \"o filme é excelente e muito divertido\", \"não gostei do enredo\",\n",
        "    \"a atuação foi brilhante\", \"péssimo! perdi meu tempo assistindo\",\n",
        "    \"a história é ok, mas nada de mais\", \"filme horrível, nem vale a pena\",\n",
        "    \"uma obra-prima da sétima arte\", \"o filme tem um final surpreendente e emocionante\",\n",
        "    \"este é o pior filme que já vi na vida\", \"excelente direção e fotografia\",\n",
        "    \"não recomendo, um lixo\", \"filme maravilhoso, amei\", \"sem graça e previsível\",\n",
        "    \"simplesmente incrível, o melhor filme do ano\", \"que filme ruim, nao entendi a hype\",\n",
        "    \"espetacular, recomendo a todos\"\n",
        "] * 20 # Aumentando o dataset para 320 amostras\n",
        "\n",
        "labels = ([\"positivo\", \"negativo\", \"positivo\", \"negativo\", \"neutro\", \"negativo\", \"positivo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\"] * 20)\n",
        "\n",
        "# Separando dados em treino e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(corpus, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Vetorização dos textos usando TF-IDF com n-grams\n",
        "# Incluindo 'ngram_range' para capturar frases de 1 e 2 palavras\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=500)\n",
        "X_treino_vetorizado = vectorizer.fit_transform(X_treino)\n",
        "X_teste_vetorizado = vectorizer.transform(X_teste)"
      ],
      "metadata": {
        "id": "ZDXbaO3qisly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A perfeição imediata prova o ponto central do roteiro : a qualidade dos dados é tão importante (ou mais) quanto o próprio algoritmo. O trabalho árduo na coleta, balanceamento e engenharia de features (n-grams) elimina a necessidade de otimização complexa inicial."
      ],
      "metadata": {
        "id": "CZZpHXMUnnCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando e treinando o modelo inicial (com parâmetros padrão)\n",
        "modelo_base = SVC()\n",
        "modelo_base.fit(X_treino_vetorizado, y_treino)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "previsoes = modelo_base.predict(X_teste_vetorizado)\n",
        "\n",
        "# Avaliando o modelo inicial\n",
        "print(\"### Análise Inicial do Modelo (linha de base) ###\\n\")\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_teste, previsoes, zero_division=0))\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_teste, previsoes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkr2J5vAizxT",
        "outputId": "82dd1e15-bdfa-493f-bed4-a96e24733943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Análise Inicial do Modelo (linha de base) ###\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      1.00      1.00        28\n",
            "      neutro       1.00      1.00      1.00         4\n",
            "    positivo       1.00      1.00      1.00        32\n",
            "\n",
            "    accuracy                           1.00        64\n",
            "   macro avg       1.00      1.00      1.00        64\n",
            "weighted avg       1.00      1.00      1.00        64\n",
            "\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[28  0  0]\n",
            " [ 0  4  0]\n",
            " [ 0  0 32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo com validação cruzada\n",
        "# Usamos o modelo base novamente para a avaliação\n",
        "scores = cross_val_score(modelo_base, X_treino_vetorizado, y_treino, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(\"\\n### Avaliação com Validação Cruzada ###\\n\")\n",
        "print(f\"Scores para cada 'fold': {scores.round(2)}\")\n",
        "print(f\"Média do F1-score com Validação Cruzada: {scores.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBvmDPXQi1FZ",
        "outputId": "0acab214-b653-487d-d201-58452e777bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Avaliação com Validação Cruzada ###\n",
            "\n",
            "Scores para cada 'fold': [1. 1. 1. 1. 1.]\n",
            "Média do F1-score com Validação Cruzada: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validação da Generalização: No Exemplo 1, scores inconsistentes (ex: $0.20, 0.80$) indicavam instabilidade. Neste caso, scores uniformes provam que o modelo não está superajustado (overfitting) a uma única divisão específica dos dados, mas sim que aprendeu padrões de sentimento verdadeiramente generalizáveis2.Confirmação do Potencial do Dataset: A Validação Cruzada confirma que o esforço em aumentar e balancear o dataset, juntamente com o pré-processamento (n-grams), foi a chave para construir um modelo confiável e estável. O modelo é robusto porque a qualidade da sua base de aprendizado é alta."
      ],
      "metadata": {
        "id": "bPnroynnnzYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os hiperparâmetros que queremos testar\n",
        "# 'C' controla a regularização e 'gamma' afeta a \"curvatura\" da fronteira de decisão\n",
        "parametros = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Criando o objeto GridSearchCV\n",
        "# cv=5 para uma avaliação mais robusta\n",
        "grid_search = GridSearchCV(SVC(), parametros, cv=5, scoring='f1_macro')\n",
        "\n",
        "# Executando a busca na \"grade\"\n",
        "print(\"\\n### Buscando os Melhores Hiperparâmetros... ###\")\n",
        "grid_search.fit(X_treino_vetorizado, y_treino)\n",
        "\n",
        "# Exibindo os melhores resultados\n",
        "print(\"\\nBusca Concluída!\")\n",
        "print(f\"Melhores parâmetros encontrados: {grid_search.best_params_}\")\n",
        "print(f\"Melhor pontuação (F1-score) encontrada: {grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Avaliando o modelo otimizado no conjunto de teste\n",
        "modelo_otimizado = grid_search.best_estimator_\n",
        "previsoes_otimizadas = modelo_otimizado.predict(X_teste_vetorizado)\n",
        "\n",
        "print(\"\\n### Análise do Modelo Otimizado (comparação) ###\\n\")\n",
        "print(\"Relatório de Classificação do Modelo Otimizado:\")\n",
        "print(classification_report(y_teste, previsoes_otimizadas, zero_division=0))\n",
        "print(\"\\nMatriz de Confusão do Modelo Otimizado:\")\n",
        "print(confusion_matrix(y_teste, previsoes_otimizadas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6mkDzl2i5jL",
        "outputId": "82146c57-1588-4230-fe76-3a73c430a045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Buscando os Melhores Hiperparâmetros... ###\n",
            "\n",
            "Busca Concluída!\n",
            "Melhores parâmetros encontrados: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Melhor pontuação (F1-score) encontrada: 1.00\n",
            "\n",
            "### Análise do Modelo Otimizado (comparação) ###\n",
            "\n",
            "Relatório de Classificação do Modelo Otimizado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      1.00      1.00        28\n",
            "      neutro       1.00      1.00      1.00         4\n",
            "    positivo       1.00      1.00      1.00        32\n",
            "\n",
            "    accuracy                           1.00        64\n",
            "   macro avg       1.00      1.00      1.00        64\n",
            "weighted avg       1.00      1.00      1.00        64\n",
            "\n",
            "\n",
            "Matriz de Confusão do Modelo Otimizado:\n",
            "[[28  0  0]\n",
            " [ 0  4  0]\n",
            " [ 0  0 32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ponto de Saturação: Quando um modelo já atinge uma performance muito próxima de 100%, há pouco ou nenhum espaço para melhoria. O algoritmo SVC base, alimentado com dados de alta qualidade e n-grams, já encontrou uma fronteira de decisão que separa as classes com altíssima precisão.Ajuste Mínimo: Se houver alguma mudança nos resultados, ela será minúscula (ex: F1-score de $0.99$ para $0.995$) ou pode até mesmo ser uma pequena queda, indicando que a otimização pode ter tentado ajustar o modelo demais (leve overfitting) ao conjunto de treino.Qual é o Valor da Otimização Neste Caso?O valor da otimização com Grid Search (buscar os melhores parâmetros C, kernel, e gamma) neste cenário não está em aumentar a pontuação, mas sim em confirmar a estabilidade e a robustez do modelo."
      ],
      "metadata": {
        "id": "icHTcuEKoE9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reflexão Final: O Poder da Qualidade dos Dados\n",
        "1. Qual Foi a Principal Lição que Você Tirou Desses Dois Cenários?\n",
        "A principal lição é: A Qualidade e a Quantidade dos Dados Superam a Otimização do Algoritmo."
      ],
      "metadata": {
        "id": "EwQa86rvoVtw"
      }
    }
  ]
}